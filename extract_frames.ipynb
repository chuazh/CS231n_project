{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def collect_video_framecount(action,subject,trial_num):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success:\n",
    "      success,image = vidcap1.read()\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      '''  \n",
    "      count += 1\n",
    "\n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    return count-1\n",
    "\n",
    "def collect_video_sample(action,subject,trial_num,num_frames):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    # collect kinematic data\n",
    "    filepath = act + '/kinematics/AllGestures/'\n",
    "    filename = filepath + act + '_' +subject + '00' + str(trial_num) + '.txt'\n",
    "    data = np.loadtxt(filename)\n",
    "    num_labels = data.shape[0]\n",
    "    print('total labels loaded: %d' % num_labels)\n",
    "    \n",
    "    if (num_labels>num_frames):\n",
    "          pass\n",
    "    else:\n",
    "          num_frames = num_labels\n",
    "          \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success and count<num_frames:\n",
    "      success,image = vidcap1.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_1'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_2'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "      '''\n",
    "      count += 1\n",
    "      if count%100 == 0:\n",
    "          print('capturing frame %d' % count)  \n",
    "    \n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    # only take cols 38-49 (slave left) and 57-68 (slave right)\n",
    "    \n",
    "    dataL = data[:count,38:50]\n",
    "    dataR = data[:count,57:69]\n",
    "    \n",
    "    out = np.hstack((dataL,dataR))\n",
    "    \n",
    "    print('total labels saved: %d' % out.shape[0])\n",
    "    \n",
    "    return out\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = {}\n",
    "subject_list['KT'] = [['B','C','D','E','F','G','H','I'],[[0,1,2,3],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[2,3,4],[0,1,2,4]]]\n",
    "#subject_list['KT'] = [['B'],[4]]\n",
    "\n",
    "y = np.empty((0,24))\n",
    "\n",
    "task = 'KT'\n",
    "subj = subject_list[task][0]\n",
    "trial = subject_list[task][1]\n",
    "for i in range(len(subj)):\n",
    "    for j in trial[i]:\n",
    "        num_frames = collect_video_framecount(task,subj[i],j+1)\n",
    "        out = collect_video_sample(task,subj[i],j+1,num_frames)\n",
    "        y = np.vstack((y,out))\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(y.shape)\n",
    "picklefile = open('kinematics', 'wb') \n",
    "pickle.dump(y,picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOT THIS ONLINE, NEED TO FIGURE OUT HOW TO CITE IT https://www.lfd.uci.edu/~gohlke/code/transformations.py.html\n",
    "\n",
    "def quaternion_from_matrix(matrix, isprecise=False):\n",
    "\n",
    "    M = np.array(matrix, dtype=np.float64, copy=False)[:4, :4]\n",
    "    if isprecise:\n",
    "        q = np.empty((4, ))\n",
    "        t = np.trace(M)\n",
    "        if t > M[3, 3]:\n",
    "            q[0] = t\n",
    "            q[3] = M[1, 0] - M[0, 1]\n",
    "            q[2] = M[0, 2] - M[2, 0]\n",
    "            q[1] = M[2, 1] - M[1, 2]\n",
    "        else:\n",
    "            i, j, k = 0, 1, 2\n",
    "            if M[1, 1] > M[0, 0]:\n",
    "                i, j, k = 1, 2, 0\n",
    "            if M[2, 2] > M[i, i]:\n",
    "                i, j, k = 2, 0, 1\n",
    "            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n",
    "            q[i] = t\n",
    "            q[j] = M[i, j] + M[j, i]\n",
    "            q[k] = M[k, i] + M[i, k]\n",
    "            q[3] = M[k, j] - M[j, k]\n",
    "            q = q[[3, 0, 1, 2]]\n",
    "        q *= 0.5 / math.sqrt(t * M[3, 3])\n",
    "    else:\n",
    "        m00 = M[0, 0]\n",
    "        m01 = M[0, 1]\n",
    "        m02 = M[0, 2]\n",
    "        m10 = M[1, 0]\n",
    "        m11 = M[1, 1]\n",
    "        m12 = M[1, 2]\n",
    "        m20 = M[2, 0]\n",
    "        m21 = M[2, 1]\n",
    "        m22 = M[2, 2]\n",
    "        # symmetric matrix K\n",
    "        K = np.array([[m00-m11-m22, 0.0,         0.0,         0.0],\n",
    "                         [m01+m10,     m11-m00-m22, 0.0,         0.0],\n",
    "                         [m02+m20,     m12+m21,     m22-m00-m11, 0.0],\n",
    "                         [m21-m12,     m02-m20,     m10-m01,     m00+m11+m22]])\n",
    "        K /= 3.0\n",
    "        # quaternion is eigenvector of K that corresponds to largest eigenvalue\n",
    "        w, V = np.linalg.eigh(K)\n",
    "        q = V[[3, 0, 1, 2], np.argmax(w)]\n",
    "    if q[0] < 0.0:\n",
    "        np.negative(q, q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Knot_Tying/video/Knot_Tying_B001_capture1.avi\n",
      "total frame count : 1750\n",
      "total labels loaded: 1735\n",
      "(1735, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_B002_capture1.avi\n",
      "total frame count : 1486\n",
      "total labels loaded: 1480\n",
      "(1480, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_B003_capture1.avi\n",
      "total frame count : 1615\n",
      "total labels loaded: 1612\n",
      "(1612, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_B004_capture1.avi\n",
      "total frame count : 1826\n",
      "total labels loaded: 1820\n",
      "(1820, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_C001_capture1.avi\n",
      "total frame count : 1234\n",
      "total labels loaded: 1227\n",
      "(1227, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_C002_capture1.avi\n",
      "total frame count : 1074\n",
      "total labels loaded: 1068\n",
      "(1068, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_C003_capture1.avi\n",
      "total frame count : 1079\n",
      "total labels loaded: 1073\n",
      "(1073, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_C004_capture1.avi\n",
      "total frame count : 1398\n",
      "total labels loaded: 1383\n",
      "(1383, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_C005_capture1.avi\n",
      "total frame count : 1156\n",
      "total labels loaded: 1150\n",
      "(1150, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_D001_capture1.avi\n",
      "total frame count : 1404\n",
      "total labels loaded: 1399\n",
      "(1399, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_D002_capture1.avi\n",
      "total frame count : 1247\n",
      "total labels loaded: 1241\n",
      "(1241, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_D003_capture1.avi\n",
      "total frame count : 1408\n",
      "total labels loaded: 1402\n",
      "(1402, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_D004_capture1.avi\n",
      "total frame count : 1055\n",
      "total labels loaded: 1049\n",
      "(1049, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_D005_capture1.avi\n",
      "total frame count : 1272\n",
      "total labels loaded: 1256\n",
      "(1256, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_E001_capture1.avi\n",
      "total frame count : 1598\n",
      "total labels loaded: 1592\n",
      "(1592, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_E002_capture1.avi\n",
      "total frame count : 1303\n",
      "total labels loaded: 1297\n",
      "(1297, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_E003_capture1.avi\n",
      "total frame count : 1420\n",
      "total labels loaded: 1413\n",
      "(1413, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_E004_capture1.avi\n",
      "total frame count : 1387\n",
      "total labels loaded: 1371\n",
      "(1371, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_E005_capture1.avi\n",
      "total frame count : 1263\n",
      "total labels loaded: 1257\n",
      "(1257, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_F001_capture1.avi\n",
      "total frame count : 926\n",
      "total labels loaded: 920\n",
      "(920, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_F002_capture1.avi\n",
      "total frame count : 1018\n",
      "total labels loaded: 1012\n",
      "(1012, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_F003_capture1.avi\n",
      "total frame count : 2728\n",
      "total labels loaded: 2722\n",
      "(2722, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_F004_capture1.avi\n",
      "total frame count : 1836\n",
      "total labels loaded: 1830\n",
      "(1830, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_F005_capture1.avi\n",
      "total frame count : 1380\n",
      "total labels loaded: 1849\n",
      "(1379, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_G001_capture1.avi\n",
      "total frame count : 2374\n",
      "total labels loaded: 2369\n",
      "(2369, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_G002_capture1.avi\n",
      "total frame count : 2287\n",
      "total labels loaded: 2282\n",
      "(2282, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_G003_capture1.avi\n",
      "total frame count : 2429\n",
      "total labels loaded: 2415\n",
      "(2415, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_G004_capture1.avi\n",
      "total frame count : 3867\n",
      "total labels loaded: 3853\n",
      "(3853, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_G005_capture1.avi\n",
      "total frame count : 1701\n",
      "total labels loaded: 1696\n",
      "(1696, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_H003_capture1.avi\n",
      "total frame count : 1641\n",
      "total labels loaded: 1635\n",
      "(1635, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_H004_capture1.avi\n",
      "total frame count : 2256\n",
      "total labels loaded: 2251\n",
      "(2251, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_H005_capture1.avi\n",
      "total frame count : 1958\n",
      "total labels loaded: 1952\n",
      "(1952, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_I001_capture1.avi\n",
      "total frame count : 2335\n",
      "total labels loaded: 2329\n",
      "(2329, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_I002_capture1.avi\n",
      "total frame count : 2433\n",
      "total labels loaded: 2426\n",
      "(2426, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_I003_capture1.avi\n",
      "total frame count : 2070\n",
      "total labels loaded: 2063\n",
      "(2063, 14)\n",
      "reading Knot_Tying/video/Knot_Tying_I005_capture1.avi\n",
      "total frame count : 2661\n",
      "total labels loaded: 2655\n",
      "(2655, 14)\n",
      "(61614, 14)\n"
     ]
    }
   ],
   "source": [
    "subject_list = {}\n",
    "subject_list['KT'] = [['B','C','D','E','F','G','H','I'],[[0,1,2,3],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[2,3,4],[0,1,2,4]]]\n",
    "\n",
    "task = 'KT'\n",
    "act = 'Knot_Tying'\n",
    "subj = subject_list[task][0]\n",
    "trial = subject_list[task][1]\n",
    "\n",
    "y = np.empty((0,14)) # 6 for position, 24 for direction cosines, 14 for quaternion\n",
    "\n",
    "index_dict = {}\n",
    "\n",
    "for i in range(len(subj)):\n",
    "    for j in trial[i]:\n",
    "        # collect kinematic data\n",
    "        count = collect_video_framecount(task,subj[i],j+1)\n",
    "        filepath = act + '/kinematics/AllGestures/'\n",
    "        filename = filepath + act + '_' + subj[i] + '00' + str(j+1) + '.txt'\n",
    "        data = np.loadtxt(filename)\n",
    "        \n",
    "        r_test = data[0, 3:12]\n",
    "        \n",
    "        num_labels = data.shape[0]\n",
    "        print('total labels loaded: %d' % num_labels)\n",
    "        dataL_pos = data[:count,39:42]\n",
    "        dataR_pos = data[:count,57:60]\n",
    "        \n",
    "        dataL_rot = data[:count, 41:50]\n",
    "        dataR_rot = data[:count, 60:69]\n",
    "        \n",
    "        # now we change the representation of the rotation to quaternion\n",
    "        N = dataL_rot.shape[0]\n",
    "        dataL_quat = np.zeros((N, 4))\n",
    "        dataR_quat = np.zeros((N, 4))\n",
    "        for k in range(N):\n",
    "            L_rot = np.asarray(dataL_rot[k, :]).reshape((3,3))\n",
    "            R_rot = np.asarray(dataR_rot[k, :]).reshape((3,3))\n",
    "\n",
    "            dataL_quat[k,:] = quaternion_from_matrix(L_rot)\n",
    "            dataR_quat[k,:] = quaternion_from_matrix(R_rot)\n",
    "        \n",
    "        dataL = np.hstack((dataL_pos, dataL_quat))\n",
    "        dataR = np.hstack((dataR_pos, dataR_quat))\n",
    "        out = np.hstack((dataL,dataR))\n",
    "        print(out.shape)\n",
    "        \n",
    "        index_dict[subj[i] + '00' + str(j+1)] = list(range(y.shape[0], y.shape[0] + out.shape[0]))\n",
    "        \n",
    "        y = np.vstack((y,out))\n",
    "import pickle\n",
    "\n",
    "print(y.shape)\n",
    "picklefile = open('kinematics', 'wb') \n",
    "pickle.dump(y,picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image files: 61614\n",
      "shape of label data: 61614x14\n",
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# functions to downsize the images and compile them into a dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from natsort import humansorted\n",
    "import pdb\n",
    "import random\n",
    "\n",
    "\n",
    "class JIGSAWDataset(Dataset):\n",
    "\n",
    "    def __init__(self, y, sortedFilelist , transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            sortedFilelist (string): sorted list of filenames.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = y\n",
    "        self.sortedlist = sortedFilelist\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.sortedlist[idx]\n",
    "        #print('opening image ' +  img_name)\n",
    "        image = Image.open(img_name,'r')\n",
    "        label = self.labels[idx,:]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample =  (image,label)\n",
    "\n",
    "        return sample\n",
    "\n",
    "def load_dataset():\n",
    "    \n",
    "    data_path = 'data'\n",
    "    picklefile = open(\"kinematics\", \"rb\" )\n",
    "    \n",
    "    num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "    print('num image files: %d' % num_files)\n",
    "    \n",
    "    trans_height = 10 \n",
    "    trans_width = 15\n",
    "    \n",
    "    trans = T.Compose([\n",
    "                T.Resize((trans_height,trans_width), interpolation=2),\n",
    "                T.ToTensor()])\n",
    "    \n",
    "#     trans = T.Compose([\n",
    "#                 T.CenterCrop(240),\n",
    "#                 T.Resize((input_size), interpolation=2),\n",
    "#                 T.ToTensor(),\n",
    "#                 T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "    transy = T.Compose([T.ToTensor()])\n",
    "\n",
    "    y = pickle.load(picklefile)\n",
    "    print('shape of label data: %dx%d' % (y.shape[0],y.shape[1]))\n",
    "    picklefile.close()\n",
    "    \n",
    "    file_list = glob.glob('data/*.png')\n",
    "    sortedlist =  humansorted(file_list)\n",
    "    \n",
    "    dataset = JIGSAWDataset(y,sortedlist,transform = trans)\n",
    "    \n",
    "    num_train_trials = 3\n",
    "    num_val_trials = 1\n",
    "        \n",
    "    range_total = np.asarray(random.sample(list(index_dict.values()), k=(num_train_trials + num_val_trials)))\n",
    "    range_train = list(range_total[:num_train_trials].flatten())[0]\n",
    "    range_val = list(range_total[num_train_trials:num_train_trials+num_val_trials].flatten())[0]\n",
    "    \n",
    "    sortedlist_seq = [ sortedlist[i] for i in range_val]\n",
    "    seq_dataset = JIGSAWDataset(y[range_val,:],sortedlist_seq,transform = trans)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range_train)\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range_val)\n",
    "    )\n",
    "    \n",
    "    seq_loader = DataLoader(\n",
    "        seq_dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SequentialSampler(seq_dataset)\n",
    "    )\n",
    "    \n",
    "    return train_loader,val_loader, seq_loader\n",
    "    \n",
    "loader_train,loader_val,loader_seq = load_dataset()\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "\n",
    "    print('Checking accuracy on validation set')\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "        print('MSE loss is: %f ' % loss)\n",
    "        \n",
    "def check_accuracy_vis(loader, model):\n",
    "\n",
    "    print('Checking accuracy on sequential validation set')\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    count = 0\n",
    "    plt.figure()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "            loss = loss_fn(scores,y)\n",
    "            plt.plot(range(count, len(scores) + count), scores.numpy()[:,0], 'b')\n",
    "            plt.plot(range(count, len(scores) + count), y.numpy()[:,0], 'r')\n",
    "            count = count + len(scores)\n",
    "\n",
    "        print('MSE loss is: %f ' % loss)\n",
    "        plt.show()\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % 5 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "#                 check_accuracy_part34(loader_train, model)\n",
    "#                 print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 10\n",
      "7 4\n",
      "4 3\n",
      "linear input dim required:  936\n",
      "Iteration 0, loss = 59.1014\n",
      "Iteration 5, loss = 13.4600\n",
      "Iteration 10, loss = 10.8368\n",
      "Iteration 15, loss = 6.5730\n",
      "Iteration 20, loss = 6.0784\n",
      "Iteration 25, loss = 3.0655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-22216a092b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# You should get at least 70% accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-4b9874a747db>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-c7383a545430>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0msortedlist\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhumansorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortedlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# These 2 helper functions non-recursively glob inside a literal directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "channel_3 = 64\n",
    "hidden_size = 1000\n",
    "learning_rate = 1e-3\n",
    "reg = 1e-5\n",
    "\n",
    "# computing the output from the conv nets\n",
    "pad1 = 2 \n",
    "filt1 = 5\n",
    "im_H = 10\n",
    "im_W = 15\n",
    "stride1 = 1\n",
    "wout1 = (im_W + 2*pad1 - filt1 )/stride1 + 1\n",
    "hout1 = (im_H + 2*pad1 - filt1 )/stride1 + 1\n",
    "print('%d %d' %(wout1,hout1))\n",
    "pad2 = 1\n",
    "filt2 = 5\n",
    "stride2 =2\n",
    "wout2 = (wout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "hout2 = (hout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "print('%d %d' %(wout2,hout2))\n",
    "pad3 = 1\n",
    "filt3 = 2\n",
    "stride3 = 2\n",
    "wout3 = (wout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "hout3 = (hout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "print('%d %d' %(wout3,hout3))\n",
    "linear_input_dim = int(channel_3*hout3*wout3)\n",
    "print('linear input dim required: ' ,linear_input_dim)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,channel_1,filt1,padding=pad1,stride = stride1),\n",
    "    nn.BatchNorm2d(channel_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1,channel_2,filt2,padding=pad2, stride = stride2),\n",
    "    nn.BatchNorm2d(channel_2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_2,channel_3,filt3,padding=pad3,stride = stride3),\n",
    "    nn.BatchNorm2d(channel_3),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(768,hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,14),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate, weight_decay = reg)\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on sequential validation set\n",
      "MSE loss is: 0.059604 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "check_accuracy_vis(loader_seq, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = 'data'\n",
    "picklefile = open(\"kinematics\", \"rb\" )\n",
    "\n",
    "num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "print(num_files)\n",
    "\n",
    "trans = T.Compose([\n",
    "            T.Resize((10,15), interpolation=2),\n",
    "            T.ToTensor()])\n",
    "transy = T.Compose([T.ToTensor()])\n",
    "transr = T.Compose([T.CenterCrop(240),T.Resize((224,224), interpolation=2)])\n",
    "\n",
    "image = Image.open('data/G_5_1_918_KT.png','r')\n",
    "print(image)\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "image = transr(image)\n",
    "plt.imshow(image)\n",
    "\n",
    "'''\n",
    "y = pickle.load(picklefile)\n",
    "picklefile.close()\n",
    "\n",
    "dataset = JIGSAWDataset(y,data_path,transform = trans)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
