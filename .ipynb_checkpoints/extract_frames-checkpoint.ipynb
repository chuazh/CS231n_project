{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def collect_video_framecount(action,subject,trial_num):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success:\n",
    "      success,image = vidcap1.read()\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      '''  \n",
    "      count += 1\n",
    "\n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    return count-1\n",
    "\n",
    "def collect_video_sample(action,subject,trial_num,num_frames):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    # collect kinematic data\n",
    "    filepath = act + '/kinematics/AllGestures/'\n",
    "    filename = filepath + act + '_' +subject + '00' + str(trial_num) + '.txt'\n",
    "    data = np.loadtxt(filename)\n",
    "    num_labels = data.shape[0]\n",
    "    print('total labels loaded: %d' % num_labels)\n",
    "    \n",
    "    if (num_labels>num_frames):\n",
    "          pass\n",
    "    else:\n",
    "          num_frames = num_labels\n",
    "          \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success and count<num_frames:\n",
    "      success,image = vidcap1.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_1'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_2'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "      '''\n",
    "      count += 1\n",
    "      if count%100 == 0:\n",
    "          print('capturing frame %d' % count)  \n",
    "    \n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    # only take cols 38-49 (slave left) and 57-68 (slave right)\n",
    "    \n",
    "    dataL = data[:count,38:50]\n",
    "    dataR = data[:count,57:69]\n",
    "    \n",
    "    out = np.hstack((dataL,dataR))\n",
    "    \n",
    "    print('total labels saved: %d' % out.shape[0])\n",
    "    \n",
    "    return out\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Knot_Tying/video/Knot_Tying_B001_capture1.avi\n",
      "total frame count : 1750\n",
      "reading Knot_Tying/video/Knot_Tying_B001_capture1.avi\n",
      "total labels loaded: 1735\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-aa54d7e219b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_video_framecount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_video_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-31ba51b99431>\u001b[0m in \u001b[0;36mcollect_video_sample\u001b[0;34m(action, subject, trial_num, num_frames)\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mwrite_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_1'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_%d_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_name\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# save frame as png file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       '''\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subject_list = {}\n",
    "subject_list['KT'] = [['B','C','D','E','F','G','H','I'],[[0,1,2,3],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4],[2,3,4],[0,1,2,4]]]\n",
    "#subject_list['KT'] = [['B'],[4]]\n",
    "\n",
    "y = np.empty((0,22))\n",
    "\n",
    "task = 'KT'\n",
    "subj = subject_list[task][0]\n",
    "trial = subject_list[task][1]\n",
    "for i in range(len(subj)):\n",
    "    for j in trial[i]:\n",
    "        num_frames = collect_video_framecount(task,subj[i],j+1)\n",
    "        out = collect_video_sample(task,subj[i],j+1,num_frames)\n",
    "        y = np.vstack((y,out))\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(y.shape)\n",
    "picklefile = open('kinematics', 'wb') \n",
    "pickle.dump(y,picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subject_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1621c685d259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'KT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Knot_Tying'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subject_list' is not defined"
     ]
    }
   ],
   "source": [
    "task = 'KT'\n",
    "act = 'Knot_Tying'\n",
    "subj = subject_list[task][0]\n",
    "trial = subject_list[task][1]\n",
    "\n",
    "y = np.empty((0,6))\n",
    "\n",
    "for i in range(len(subj)):\n",
    "    for j in trial[i]:\n",
    "        # collect kinematic data\n",
    "        count = collect_video_framecount(task,subj[i],j+1)\n",
    "        filepath = act + '/kinematics/AllGestures/'\n",
    "        filename = filepath + act + '_' + subj[i] + '00' + str(j+1) + '.txt'\n",
    "        data = np.loadtxt(filename)\n",
    "        num_labels = data.shape[0]\n",
    "        print('total labels loaded: %d' % num_labels)\n",
    "        dataL = data[:count,38:41]\n",
    "        dataR = data[:count,57:60]\n",
    "        out = np.hstack((dataL,dataR))\n",
    "        print(out.shape)\n",
    "        y = np.vstack((y,out))\n",
    "import pickle\n",
    "\n",
    "print(y.shape)\n",
    "picklefile = open('kinematics', 'wb') \n",
    "pickle.dump(y,picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61614\n",
      "(61614, 6)\n",
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# functions to downsize the images and compile them into a dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import pdb\n",
    "\n",
    "class JIGSAWDataset(Dataset):\n",
    "\n",
    "    def __init__(self, y, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = y\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        file_list = glob.glob('data/*.png')\n",
    "        img_name = file_list[idx]\n",
    "        #print('opening image ' +  img_name)\n",
    "        image = Image.open(img_name,'r')\n",
    "        label = self.labels[idx,:]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample =  (image,label)\n",
    "\n",
    "        return sample\n",
    "\n",
    "def load_dataset():\n",
    "    \n",
    "    data_path = 'data'\n",
    "    picklefile = open(\"kinematics\", \"rb\" )\n",
    "    \n",
    "    num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "    print(num_files)\n",
    "    \n",
    "    trans = T.Compose([\n",
    "                T.Resize((60,80), interpolation=2),\n",
    "                T.ToTensor()])\n",
    "    transy = T.Compose([T.ToTensor()])\n",
    "\n",
    "    y = pickle.load(picklefile)\n",
    "    print(y.shape)\n",
    "    picklefile.close()\n",
    "    \n",
    "    dataset = JIGSAWDataset(y,data_path,transform = trans)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range(num_files-2000))\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=25,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range(num_files-2000,num_files))\n",
    "    )\n",
    "    \n",
    "    return train_loader,val_loader\n",
    "    \n",
    "loader_train,loader_val = load_dataset()\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "\n",
    "    print('Checking accuracy on validation set')\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "        print('MSE loss is: %d ' % loss)\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % 5 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                #check_accuracy_part34(loader_train, model)\n",
    "                print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 60\n",
      "39 29\n",
      "20 15\n",
      "linear input dim required:  20916\n",
      "Iteration 0, loss = 10.6527\n",
      "\n",
      "Iteration 5, loss = 12.9713\n",
      "\n",
      "Iteration 10, loss = 2.2988\n",
      "\n",
      "Iteration 15, loss = 1.6261\n",
      "\n",
      "Iteration 20, loss = 0.6415\n",
      "\n",
      "Iteration 25, loss = 1.1231\n",
      "\n",
      "Iteration 30, loss = 0.3544\n",
      "\n",
      "Iteration 35, loss = 0.4584\n",
      "\n",
      "Iteration 40, loss = 0.4296\n",
      "\n",
      "Iteration 45, loss = 0.3156\n",
      "\n",
      "Iteration 50, loss = 0.2745\n",
      "\n",
      "Iteration 55, loss = 0.1442\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6ce73999bba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# You should get at least 70% accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f602125cb5ce>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-65cf6436b3cf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print('opening image ' +  img_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "channel_3 = 64\n",
    "hidden_size = 1000\n",
    "learning_rate = 1e-3\n",
    "reg = 1e-5\n",
    "\n",
    "# computing the output from the conv nets\n",
    "pad1 = 2 \n",
    "filt1 = 5\n",
    "im_H = 60\n",
    "im_W = 80\n",
    "stride1 = 1\n",
    "wout1 = (im_W + 2*pad1 - filt1 )/stride1 + 1\n",
    "hout1 = (im_H + 2*pad1 - filt1 )/stride1 + 1\n",
    "print('%d %d' %(wout1,hout1))\n",
    "pad2 = 1\n",
    "filt2 = 5\n",
    "stride2 =2\n",
    "wout2 = (wout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "hout2 = (hout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "print('%d %d' %(wout2,hout2))\n",
    "pad3 = 1\n",
    "filt3 = 2\n",
    "stride3 = 2\n",
    "wout3 = (wout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "hout3 = (hout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "print('%d %d' %(wout3,hout3))\n",
    "linear_input_dim = int(channel_3*hout3*wout3)\n",
    "print('linear input dim required: ' ,linear_input_dim)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,channel_1,filt1,padding=pad1,stride = stride1),\n",
    "    nn.BatchNorm2d(channel_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1,channel_2,filt2,padding=pad2, stride = stride2),\n",
    "    nn.BatchNorm2d(channel_2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_2,channel_3,filt3,padding=pad3,stride = stride3),\n",
    "    nn.BatchNorm2d(channel_3),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(19200,hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,6),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate, weight_decay = reg)\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6647\n",
      "tensor([[[0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.1059, 0.1176, 0.1176],\n",
      "         ...,\n",
      "         [0.0667, 0.1294, 0.1569,  ..., 0.3804, 0.3647, 0.3098],\n",
      "         [0.0627, 0.1294, 0.1451,  ..., 0.3725, 0.3569, 0.3020],\n",
      "         [0.0627, 0.1294, 0.1451,  ..., 0.3804, 0.3647, 0.3098]],\n",
      "\n",
      "        [[0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.1255, 0.1176, 0.1176],\n",
      "         ...,\n",
      "         [0.0627, 0.1294, 0.1686,  ..., 0.0902, 0.0824, 0.0941],\n",
      "         [0.0588, 0.1255, 0.1569,  ..., 0.0784, 0.0863, 0.0980],\n",
      "         [0.0588, 0.1255, 0.1569,  ..., 0.0863, 0.0941, 0.1059]],\n",
      "\n",
      "        [[0.0275, 0.0510, 0.0627,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.0863, 0.0980, 0.0980],\n",
      "         ...,\n",
      "         [0.0706, 0.1412, 0.1765,  ..., 0.0039, 0.0078, 0.0667],\n",
      "         [0.0667, 0.1373, 0.1647,  ..., 0.0039, 0.0118, 0.0745],\n",
      "         [0.0667, 0.1373, 0.1647,  ..., 0.0118, 0.0235, 0.0863]]])\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "picklefile = open(\"kinematics\", \"rb\" )\n",
    "\n",
    "num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "print(num_files)\n",
    "\n",
    "trans = T.Compose([\n",
    "            T.Resize((60,80), interpolation=2),\n",
    "            T.ToTensor()])\n",
    "transy = T.Compose([T.ToTensor()])\n",
    "\n",
    "y = pickle.load(picklefile)\n",
    "picklefile.close()\n",
    "\n",
    "dataset = JIGSAWDataset(y,data_path,transform = trans)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
