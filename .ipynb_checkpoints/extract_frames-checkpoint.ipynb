{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def collect_video_framecount(action,subject,trial_num):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success:\n",
    "      success,image = vidcap1.read()\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      '''  \n",
    "      count += 1\n",
    "\n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    return count-1\n",
    "\n",
    "def collect_video_sample(action,subject,trial_num,num_frames):\n",
    "    \n",
    "    action_dict = {'KT':'Knot_Tying','S':'Suturing','NP': 'Needle_Passing'}\n",
    "    \n",
    "    act = action_dict[action]\n",
    "\n",
    "    filename1 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture1.avi'\n",
    "    filename2 = act+'/video/'+act+'_'+subject+'00'+str(trial_num)+'_capture2.avi'\n",
    "    \n",
    "    print('reading '+filename1)\n",
    "    \n",
    "    vidcap1 = cv2.VideoCapture(filename1)\n",
    "    vidcap2 = cv2.VideoCapture(filename2)\n",
    "    \n",
    "    # collect kinematic data\n",
    "    filepath = act + '/kinematics/AllGestures/'\n",
    "    filename = filepath + act + '_' +subject + '00' + str(trial_num) + '.txt'\n",
    "    data = np.loadtxt(filename)\n",
    "    num_labels = data.shape[0]\n",
    "    print('total labels loaded: %d' % num_labels)\n",
    "    \n",
    "    if (num_labels>num_frames):\n",
    "          pass\n",
    "    else:\n",
    "          num_frames = num_labels\n",
    "          \n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    while success and count<num_frames:\n",
    "      success,image = vidcap1.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_1'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "    \n",
    "      '''\n",
    "      success,image = vidcap2.read()\n",
    "      write_name = 'data/' + subject+'_'+str(trial_num)+'_2'+'_%d_'+ action + '.png'\n",
    "      cv2.imwrite(write_name % count, image)     # save frame as png file\n",
    "      '''\n",
    "      count += 1\n",
    "      if count%100 == 0:\n",
    "          print('capturing frame %d' % count)  \n",
    "    \n",
    "    print('total frame count : %d' % count)\n",
    "    \n",
    "    # only take cols 38-49 (slave left) and 57-68 (slave right)\n",
    "    \n",
    "    dataL = data[:count,38:49]\n",
    "    dataR = data[:count,57:68]\n",
    "    \n",
    "    out = np.hstack((dataL,dataR))\n",
    "    \n",
    "    print('total labels saved: %d' % out.shape[0])\n",
    "    \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Knot_Tying/video/Knot_Tying_B001_capture1.avi\n",
      "total frame count : 1750\n",
      "reading Knot_Tying/video/Knot_Tying_B001_capture1.avi\n",
      "total labels loaded: 1735\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "total frame count : 1735\n",
      "total labels saved: 1735\n",
      "reading Knot_Tying/video/Knot_Tying_B002_capture1.avi\n",
      "total frame count : 1486\n",
      "reading Knot_Tying/video/Knot_Tying_B002_capture1.avi\n",
      "total labels loaded: 1480\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "total frame count : 1480\n",
      "total labels saved: 1480\n",
      "reading Knot_Tying/video/Knot_Tying_B003_capture1.avi\n",
      "total frame count : 1615\n",
      "reading Knot_Tying/video/Knot_Tying_B003_capture1.avi\n",
      "total labels loaded: 1612\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "total frame count : 1612\n",
      "total labels saved: 1612\n",
      "reading Knot_Tying/video/Knot_Tying_B004_capture1.avi\n",
      "total frame count : 1826\n",
      "reading Knot_Tying/video/Knot_Tying_B004_capture1.avi\n",
      "total labels loaded: 1820\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "total frame count : 1820\n",
      "total labels saved: 1820\n",
      "reading Knot_Tying/video/Knot_Tying_C001_capture1.avi\n",
      "total frame count : 1234\n",
      "reading Knot_Tying/video/Knot_Tying_C001_capture1.avi\n",
      "total labels loaded: 1227\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "total frame count : 1227\n",
      "total labels saved: 1227\n",
      "reading Knot_Tying/video/Knot_Tying_C002_capture1.avi\n",
      "total frame count : 1074\n",
      "reading Knot_Tying/video/Knot_Tying_C002_capture1.avi\n",
      "total labels loaded: 1068\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "total frame count : 1068\n",
      "total labels saved: 1068\n",
      "reading Knot_Tying/video/Knot_Tying_C003_capture1.avi\n",
      "total frame count : 1079\n",
      "reading Knot_Tying/video/Knot_Tying_C003_capture1.avi\n",
      "total labels loaded: 1073\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "total frame count : 1073\n",
      "total labels saved: 1073\n",
      "reading Knot_Tying/video/Knot_Tying_C004_capture1.avi\n",
      "total frame count : 1398\n",
      "reading Knot_Tying/video/Knot_Tying_C004_capture1.avi\n",
      "total labels loaded: 1383\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "total frame count : 1383\n",
      "total labels saved: 1383\n",
      "reading Knot_Tying/video/Knot_Tying_C005_capture1.avi\n",
      "total frame count : 1156\n",
      "reading Knot_Tying/video/Knot_Tying_C005_capture1.avi\n",
      "total labels loaded: 1150\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "total frame count : 1150\n",
      "total labels saved: 1150\n",
      "reading Knot_Tying/video/Knot_Tying_D001_capture1.avi\n",
      "total frame count : 1404\n",
      "reading Knot_Tying/video/Knot_Tying_D001_capture1.avi\n",
      "total labels loaded: 1399\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "total frame count : 1399\n",
      "total labels saved: 1399\n",
      "reading Knot_Tying/video/Knot_Tying_D002_capture1.avi\n",
      "total frame count : 1247\n",
      "reading Knot_Tying/video/Knot_Tying_D002_capture1.avi\n",
      "total labels loaded: 1241\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "total frame count : 1241\n",
      "total labels saved: 1241\n",
      "reading Knot_Tying/video/Knot_Tying_D003_capture1.avi\n",
      "total frame count : 1408\n",
      "reading Knot_Tying/video/Knot_Tying_D003_capture1.avi\n",
      "total labels loaded: 1402\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "total frame count : 1402\n",
      "total labels saved: 1402\n",
      "reading Knot_Tying/video/Knot_Tying_D004_capture1.avi\n",
      "total frame count : 1055\n",
      "reading Knot_Tying/video/Knot_Tying_D004_capture1.avi\n",
      "total labels loaded: 1049\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "total frame count : 1049\n",
      "total labels saved: 1049\n",
      "reading Knot_Tying/video/Knot_Tying_D005_capture1.avi\n",
      "total frame count : 1272\n",
      "reading Knot_Tying/video/Knot_Tying_D005_capture1.avi\n",
      "total labels loaded: 1256\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "total frame count : 1256\n",
      "total labels saved: 1256\n",
      "reading Knot_Tying/video/Knot_Tying_E001_capture1.avi\n",
      "total frame count : 1598\n",
      "reading Knot_Tying/video/Knot_Tying_E001_capture1.avi\n",
      "total labels loaded: 1592\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "total frame count : 1592\n",
      "total labels saved: 1592\n",
      "reading Knot_Tying/video/Knot_Tying_E002_capture1.avi\n",
      "total frame count : 1303\n",
      "reading Knot_Tying/video/Knot_Tying_E002_capture1.avi\n",
      "total labels loaded: 1297\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "total frame count : 1297\n",
      "total labels saved: 1297\n",
      "reading Knot_Tying/video/Knot_Tying_E003_capture1.avi\n",
      "total frame count : 1420\n",
      "reading Knot_Tying/video/Knot_Tying_E003_capture1.avi\n",
      "total labels loaded: 1413\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "total frame count : 1413\n",
      "total labels saved: 1413\n",
      "reading Knot_Tying/video/Knot_Tying_E004_capture1.avi\n",
      "total frame count : 1387\n",
      "reading Knot_Tying/video/Knot_Tying_E004_capture1.avi\n",
      "total labels loaded: 1371\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "total frame count : 1371\n",
      "total labels saved: 1371\n",
      "reading Knot_Tying/video/Knot_Tying_E005_capture1.avi\n",
      "total frame count : 1263\n",
      "reading Knot_Tying/video/Knot_Tying_E005_capture1.avi\n",
      "total labels loaded: 1257\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "total frame count : 1257\n",
      "total labels saved: 1257\n",
      "reading Knot_Tying/video/Knot_Tying_F001_capture1.avi\n",
      "total frame count : 926\n",
      "reading Knot_Tying/video/Knot_Tying_F001_capture1.avi\n",
      "total labels loaded: 920\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "total frame count : 920\n",
      "total labels saved: 920\n",
      "reading Knot_Tying/video/Knot_Tying_F002_capture1.avi\n",
      "total frame count : 1018\n",
      "reading Knot_Tying/video/Knot_Tying_F002_capture1.avi\n",
      "total labels loaded: 1012\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "total frame count : 1012\n",
      "total labels saved: 1012\n",
      "reading Knot_Tying/video/Knot_Tying_F003_capture1.avi\n",
      "total frame count : 2728\n",
      "reading Knot_Tying/video/Knot_Tying_F003_capture1.avi\n",
      "total labels loaded: 2722\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "capturing frame 1900\n",
      "capturing frame 2000\n",
      "capturing frame 2100\n",
      "capturing frame 2200\n",
      "capturing frame 2300\n",
      "capturing frame 2400\n",
      "capturing frame 2500\n",
      "capturing frame 2600\n",
      "capturing frame 2700\n",
      "total frame count : 2722\n",
      "total labels saved: 2722\n",
      "reading Knot_Tying/video/Knot_Tying_F004_capture1.avi\n",
      "total frame count : 1836\n",
      "reading Knot_Tying/video/Knot_Tying_F004_capture1.avi\n",
      "total labels loaded: 1830\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "total frame count : 1830\n",
      "total labels saved: 1830\n",
      "reading Knot_Tying/video/Knot_Tying_F005_capture1.avi\n",
      "total frame count : 1380\n",
      "reading Knot_Tying/video/Knot_Tying_F005_capture1.avi\n",
      "total labels loaded: 1849\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "total frame count : 1379\n",
      "total labels saved: 1379\n",
      "reading Knot_Tying/video/Knot_Tying_G001_capture1.avi\n",
      "total frame count : 2374\n",
      "reading Knot_Tying/video/Knot_Tying_G001_capture1.avi\n",
      "total labels loaded: 2369\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "capturing frame 1900\n",
      "capturing frame 2000\n",
      "capturing frame 2100\n",
      "capturing frame 2200\n",
      "capturing frame 2300\n",
      "total frame count : 2369\n",
      "total labels saved: 2369\n",
      "reading Knot_Tying/video/Knot_Tying_G002_capture1.avi\n",
      "total frame count : 2287\n",
      "reading Knot_Tying/video/Knot_Tying_G002_capture1.avi\n",
      "total labels loaded: 2282\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "capturing frame 1900\n",
      "capturing frame 2000\n",
      "capturing frame 2100\n",
      "capturing frame 2200\n",
      "total frame count : 2282\n",
      "total labels saved: 2282\n",
      "reading Knot_Tying/video/Knot_Tying_G003_capture1.avi\n",
      "total frame count : 2429\n",
      "reading Knot_Tying/video/Knot_Tying_G003_capture1.avi\n",
      "total labels loaded: 2415\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "capturing frame 1900\n",
      "capturing frame 2000\n",
      "capturing frame 2100\n",
      "capturing frame 2200\n",
      "capturing frame 2300\n",
      "capturing frame 2400\n",
      "total frame count : 2415\n",
      "total labels saved: 2415\n",
      "reading Knot_Tying/video/Knot_Tying_G004_capture1.avi\n",
      "total frame count : 3867\n",
      "reading Knot_Tying/video/Knot_Tying_G004_capture1.avi\n",
      "total labels loaded: 3853\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "capturing frame 1700\n",
      "capturing frame 1800\n",
      "capturing frame 1900\n",
      "capturing frame 2000\n",
      "capturing frame 2100\n",
      "capturing frame 2200\n",
      "capturing frame 2300\n",
      "capturing frame 2400\n",
      "capturing frame 2500\n",
      "capturing frame 2600\n",
      "capturing frame 2700\n",
      "capturing frame 2800\n",
      "capturing frame 2900\n",
      "capturing frame 3000\n",
      "capturing frame 3100\n",
      "capturing frame 3200\n",
      "capturing frame 3300\n",
      "capturing frame 3400\n",
      "capturing frame 3500\n",
      "capturing frame 3600\n",
      "capturing frame 3700\n",
      "capturing frame 3800\n",
      "total frame count : 3853\n",
      "total labels saved: 3853\n",
      "reading Knot_Tying/video/Knot_Tying_G005_capture1.avi\n",
      "total frame count : 1701\n",
      "reading Knot_Tying/video/Knot_Tying_G005_capture1.avi\n",
      "total labels loaded: 1696\n",
      "capturing frame 100\n",
      "capturing frame 200\n",
      "capturing frame 300\n",
      "capturing frame 400\n",
      "capturing frame 500\n",
      "capturing frame 600\n",
      "capturing frame 700\n",
      "capturing frame 800\n",
      "capturing frame 900\n",
      "capturing frame 1000\n",
      "capturing frame 1100\n",
      "capturing frame 1200\n",
      "capturing frame 1300\n",
      "capturing frame 1400\n",
      "capturing frame 1500\n",
      "capturing frame 1600\n",
      "total frame count : 1696\n",
      "total labels saved: 1696\n",
      "(46303, 22)\n"
     ]
    }
   ],
   "source": [
    "subject_list = {}\n",
    "subject_list['KT'] = [['B','C','D','E','F','G'],[4,5,5,5,5,5]]\n",
    "#subject_list['KT'] = [['B'],[4]]\n",
    "\n",
    "y = np.empty((0,22))\n",
    "\n",
    "task = 'KT'\n",
    "subj = subject_list[task][0]\n",
    "trial = subject_list[task][1]\n",
    "for i in range(len(subj)):\n",
    "    for j in range(trial[i]):\n",
    "        num_frames = collect_video_framecount(task,subj[i],j+1)\n",
    "        out = collect_video_sample(task,subj[i],j+1,num_frames)\n",
    "        y = np.vstack((y,out))\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(y.shape)\n",
    "picklefile = open('kinematics', 'ab') \n",
    "pickle.dump(y,picklefile)\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46303\n",
      "(46303, 22)\n",
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# functions to downsize the images and compile them into a dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import pdb\n",
    "\n",
    "class JIGSAWDataset(Dataset):\n",
    "\n",
    "    def __init__(self, y, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels = y\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        file_list = glob.glob('data/*.png')\n",
    "        img_name = file_list[idx]\n",
    "        #print('opening image ' +  img_name)\n",
    "        image = Image.open(img_name,'r')\n",
    "        label = self.labels[idx,:]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample =  (image,label)\n",
    "\n",
    "        return sample\n",
    "\n",
    "def load_dataset():\n",
    "    \n",
    "    data_path = 'data'\n",
    "    picklefile = open(\"kinematics\", \"rb\" )\n",
    "    \n",
    "    num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "    print(num_files)\n",
    "    \n",
    "    trans = T.Compose([\n",
    "                T.Resize((60,80), interpolation=2),\n",
    "                T.ToTensor()])\n",
    "    transy = T.Compose([T.ToTensor()])\n",
    "\n",
    "    y = pickle.load(picklefile)\n",
    "    print(y.shape)\n",
    "    picklefile.close()\n",
    "    \n",
    "    dataset = JIGSAWDataset(y,data_path,transform = trans)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range(num_files-1000))\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        sampler=sampler.SubsetRandomSampler(range(num_files-1000,num_files))\n",
    "    )\n",
    "    \n",
    "    return train_loader,val_loader\n",
    "    \n",
    "loader_train,loader_val = load_dataset()\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "\n",
    "    print('Checking accuracy on validation set')\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "        print('MSE loss is: %d ' % loss)\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "            loss = loss_fn(scores,y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % 5 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                #check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 60\n",
      "39 29\n",
      "20 15\n",
      "linear input dim required:  20916\n",
      "Iteration 0, loss = 375.2760\n",
      "\n",
      "Iteration 5, loss = 1257.7787\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-93e60a572ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# You should get at least 70% accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2cc5478a5c47>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move the model parameters to CPU/GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-afd2d73edaed>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print('opening image ' +  img_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/fnmatch.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(names, pat)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# normcase on posix is NOP. Optimize it away from the loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "channel_3 = 64\n",
    "hidden_size = 1000\n",
    "learning_rate = 1e-3\n",
    "reg = 1e-5\n",
    "\n",
    "# computing the output from the conv nets\n",
    "pad1 = 2 \n",
    "filt1 = 5\n",
    "im_H = 60\n",
    "im_W = 80\n",
    "stride1 = 1\n",
    "wout1 = (im_W + 2*pad1 - filt1 )/stride1 + 1\n",
    "hout1 = (im_H + 2*pad1 - filt1 )/stride1 + 1\n",
    "print('%d %d' %(wout1,hout1))\n",
    "pad2 = 1\n",
    "filt2 = 5\n",
    "stride2 =2\n",
    "wout2 = (wout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "hout2 = (hout1 + 2 *pad2 - filt2 )/stride2 + 1\n",
    "print('%d %d' %(wout2,hout2))\n",
    "pad3 = 1\n",
    "filt3 = 2\n",
    "stride3 = 2\n",
    "wout3 = (wout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "hout3 = (hout2 + 2 *pad3 - filt3 )/stride3 + 1\n",
    "print('%d %d' %(wout3,hout3))\n",
    "linear_input_dim = int(channel_3*hout3*wout3)\n",
    "print('linear input dim required: ' ,linear_input_dim)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,channel_1,filt1,padding=pad1,stride = stride1),\n",
    "    nn.BatchNorm2d(channel_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1,channel_2,filt2,padding=pad2, stride = stride2),\n",
    "    nn.BatchNorm2d(channel_2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_2,channel_3,filt3,padding=pad3,stride = stride3),\n",
    "    nn.BatchNorm2d(channel_3),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(19200,hidden_size),\n",
    "    nn.BatchNorm1d(hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,22),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate, weight_decay = reg)\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6647\n",
      "tensor([[[0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.1059, 0.1176, 0.1176],\n",
      "         ...,\n",
      "         [0.0667, 0.1294, 0.1569,  ..., 0.3804, 0.3647, 0.3098],\n",
      "         [0.0627, 0.1294, 0.1451,  ..., 0.3725, 0.3569, 0.3020],\n",
      "         [0.0627, 0.1294, 0.1451,  ..., 0.3804, 0.3647, 0.3098]],\n",
      "\n",
      "        [[0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.1176, 0.1176, 0.1176],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.1255, 0.1176, 0.1176],\n",
      "         ...,\n",
      "         [0.0627, 0.1294, 0.1686,  ..., 0.0902, 0.0824, 0.0941],\n",
      "         [0.0588, 0.1255, 0.1569,  ..., 0.0784, 0.0863, 0.0980],\n",
      "         [0.0588, 0.1255, 0.1569,  ..., 0.0863, 0.0941, 0.1059]],\n",
      "\n",
      "        [[0.0275, 0.0510, 0.0627,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0275, 0.0510, 0.0627,  ..., 0.0980, 0.0980, 0.0980],\n",
      "         [0.0275, 0.0471, 0.0510,  ..., 0.0863, 0.0980, 0.0980],\n",
      "         ...,\n",
      "         [0.0706, 0.1412, 0.1765,  ..., 0.0039, 0.0078, 0.0667],\n",
      "         [0.0667, 0.1373, 0.1647,  ..., 0.0039, 0.0118, 0.0745],\n",
      "         [0.0667, 0.1373, 0.1647,  ..., 0.0118, 0.0235, 0.0863]]])\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "picklefile = open(\"kinematics\", \"rb\" )\n",
    "\n",
    "num_files = len(next(os.walk('data'))[2]) #dir is your directory path as string\n",
    "print(num_files)\n",
    "\n",
    "trans = T.Compose([\n",
    "            T.Resize((60,80), interpolation=2),\n",
    "            T.ToTensor()])\n",
    "transy = T.Compose([T.ToTensor()])\n",
    "\n",
    "y = pickle.load(picklefile)\n",
    "picklefile.close()\n",
    "\n",
    "dataset = JIGSAWDataset(y,data_path,transform = trans)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
