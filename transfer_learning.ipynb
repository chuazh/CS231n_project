{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for performing transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import input_util as ip\n",
    "import transfer_models as mdl\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# preliminaries:\n",
    "input_size = 224 # for RESNET\n",
    "model_name = 'resnet'\n",
    "num_output = 6 \n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image files: 61614\n",
      "shape of label data: 61614x6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader,val_loader = ip.load_dataset(input_size)\n",
    "\n",
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train']= train_loader\n",
    "dataloaders_dict['val'] = val_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
      ")\n",
      "using device:\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_ft, input_size = mdl.initialize_model(model_name, num_output, feature_extract, use_pretrained=False)\n",
    "print(model_ft)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using device:')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.MSELoss(reduction='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "loss for iteration 5: 1.747764\n",
      "loss for iteration 10: 0.947446\n",
      "loss for iteration 15: 0.456539\n",
      "loss for iteration 20: 0.210907\n",
      "loss for iteration 25: 0.081208\n",
      "loss for iteration 30: 0.031615\n",
      "loss for iteration 35: 0.015048\n",
      "loss for iteration 40: 0.012143\n",
      "loss for iteration 45: 0.013414\n",
      "loss for iteration 50: 0.010825\n",
      "loss for iteration 55: 0.010088\n",
      "loss for iteration 60: 0.009258\n",
      "loss for iteration 65: 0.009586\n",
      "loss for iteration 70: 0.008290\n",
      "loss for iteration 75: 0.010143\n",
      "loss for iteration 80: 0.008158\n",
      "train Loss: 0.0054\n",
      "loss for iteration 5: 0.005929\n",
      "loss for iteration 10: 0.006089\n",
      "loss for iteration 15: 0.007450\n",
      "loss for iteration 20: 0.007680\n",
      "loss for iteration 25: 0.007383\n",
      "loss for iteration 30: 0.006722\n",
      "loss for iteration 35: 0.007208\n",
      "loss for iteration 40: 0.008568\n",
      "loss for iteration 45: 0.008988\n",
      "loss for iteration 50: 0.006768\n",
      "loss for iteration 55: 0.006560\n",
      "loss for iteration 60: 0.005638\n",
      "loss for iteration 65: 0.007734\n",
      "loss for iteration 70: 0.007019\n",
      "loss for iteration 75: 0.010243\n",
      "loss for iteration 80: 0.007112\n",
      "val Loss: 0.0002\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "loss for iteration 5: 0.008617\n",
      "loss for iteration 10: 0.006890\n",
      "loss for iteration 15: 0.009104\n",
      "loss for iteration 20: 0.009375\n",
      "loss for iteration 25: 0.007724\n",
      "loss for iteration 30: 0.008020\n",
      "loss for iteration 35: 0.007190\n",
      "loss for iteration 40: 0.006932\n",
      "loss for iteration 45: 0.007201\n",
      "loss for iteration 50: 0.008148\n",
      "loss for iteration 55: 0.007375\n",
      "loss for iteration 60: 0.008052\n",
      "loss for iteration 65: 0.007385\n",
      "loss for iteration 70: 0.006515\n",
      "loss for iteration 75: 0.006177\n",
      "loss for iteration 80: 0.007200\n",
      "train Loss: 0.0002\n",
      "loss for iteration 5: 0.007161\n",
      "loss for iteration 10: 0.004833\n",
      "loss for iteration 15: 0.006502\n",
      "loss for iteration 20: 0.007062\n",
      "loss for iteration 25: 0.007798\n",
      "loss for iteration 30: 0.006651\n",
      "loss for iteration 35: 0.007085\n",
      "loss for iteration 40: 0.008884\n",
      "loss for iteration 45: 0.008235\n",
      "loss for iteration 50: 0.006467\n",
      "loss for iteration 55: 0.007830\n",
      "loss for iteration 60: 0.006514\n",
      "loss for iteration 65: 0.008178\n",
      "loss for iteration 70: 0.005970\n",
      "loss for iteration 75: 0.006189\n",
      "loss for iteration 80: 0.007110\n",
      "val Loss: 0.0002\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "loss for iteration 5: 0.007759\n",
      "loss for iteration 10: 0.007942\n",
      "loss for iteration 15: 0.009135\n",
      "loss for iteration 20: 0.010674\n",
      "loss for iteration 25: 0.007059\n",
      "loss for iteration 30: 0.007946\n",
      "loss for iteration 35: 0.006498\n",
      "loss for iteration 40: 0.006134\n",
      "loss for iteration 45: 0.007084\n",
      "loss for iteration 50: 0.007584\n",
      "loss for iteration 55: 0.006654\n",
      "loss for iteration 60: 0.006052\n",
      "loss for iteration 65: 0.008077\n",
      "loss for iteration 70: 0.006572\n",
      "loss for iteration 75: 0.006859\n",
      "loss for iteration 80: 0.008286\n",
      "train Loss: 0.0002\n",
      "loss for iteration 5: 0.006613\n",
      "loss for iteration 10: 0.006503\n",
      "loss for iteration 15: 0.007154\n",
      "loss for iteration 20: 0.007856\n",
      "loss for iteration 25: 0.006789\n",
      "loss for iteration 30: 0.007155\n",
      "loss for iteration 35: 0.007374\n",
      "loss for iteration 40: 0.007124\n",
      "loss for iteration 45: 0.008140\n",
      "loss for iteration 50: 0.007071\n",
      "loss for iteration 55: 0.006665\n",
      "loss for iteration 60: 0.007176\n",
      "loss for iteration 65: 0.006812\n",
      "loss for iteration 70: 0.008846\n",
      "loss for iteration 75: 0.008509\n",
      "loss for iteration 80: 0.010743\n",
      "val Loss: 0.0002\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "loss for iteration 5: 0.007781\n",
      "loss for iteration 10: 0.005751\n",
      "loss for iteration 15: 0.007668\n",
      "loss for iteration 20: 0.005987\n",
      "loss for iteration 25: 0.006638\n",
      "loss for iteration 30: 0.006074\n",
      "loss for iteration 35: 0.007537\n",
      "loss for iteration 40: 0.005518\n",
      "loss for iteration 45: 0.006879\n",
      "loss for iteration 50: 0.006175\n",
      "loss for iteration 55: 0.007242\n",
      "loss for iteration 60: 0.004762\n",
      "loss for iteration 65: 0.006677\n",
      "loss for iteration 70: 0.006830\n",
      "loss for iteration 75: 0.006049\n",
      "loss for iteration 80: 0.005455\n",
      "train Loss: 0.0002\n",
      "loss for iteration 5: 0.007974\n",
      "loss for iteration 10: 0.005478\n",
      "loss for iteration 15: 0.008211\n",
      "loss for iteration 20: 0.006450\n",
      "loss for iteration 25: 0.005939\n",
      "loss for iteration 30: 0.005702\n",
      "loss for iteration 35: 0.007123\n",
      "loss for iteration 40: 0.008159\n",
      "loss for iteration 45: 0.007092\n",
      "loss for iteration 50: 0.007307\n",
      "loss for iteration 55: 0.006644\n",
      "loss for iteration 60: 0.006288\n",
      "loss for iteration 65: 0.005670\n",
      "loss for iteration 70: 0.005860\n",
      "loss for iteration 75: 0.007052\n",
      "loss for iteration 80: 0.005843\n",
      "val Loss: 0.0002\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "loss for iteration 5: 0.005428\n",
      "loss for iteration 10: 0.005823\n",
      "loss for iteration 15: 0.007190\n",
      "loss for iteration 20: 0.008936\n",
      "loss for iteration 25: 0.007410\n",
      "loss for iteration 30: 0.006718\n",
      "loss for iteration 35: 0.006812\n",
      "loss for iteration 40: 0.006776\n",
      "loss for iteration 45: 0.007229\n",
      "loss for iteration 50: 0.006189\n",
      "loss for iteration 55: 0.006181\n",
      "loss for iteration 60: 0.005682\n",
      "loss for iteration 65: 0.006568\n",
      "loss for iteration 70: 0.007420\n",
      "loss for iteration 75: 0.006353\n",
      "loss for iteration 80: 0.005755\n",
      "train Loss: 0.0002\n",
      "loss for iteration 5: 0.006863\n",
      "loss for iteration 10: 0.007205\n",
      "loss for iteration 15: 0.009909\n",
      "loss for iteration 20: 0.007460\n",
      "loss for iteration 25: 0.006837\n",
      "loss for iteration 30: 0.007193\n",
      "loss for iteration 35: 0.006809\n",
      "loss for iteration 40: 0.007875\n",
      "loss for iteration 45: 0.008058\n",
      "loss for iteration 50: 0.005555\n",
      "loss for iteration 55: 0.007643\n",
      "loss for iteration 60: 0.007317\n",
      "loss for iteration 65: 0.007456\n",
      "loss for iteration 70: 0.006325\n",
      "loss for iteration 75: 0.007046\n",
      "loss for iteration 80: 0.008078\n",
      "val Loss: 0.0002\n",
      "\n",
      "Training complete in 5m 3s\n",
      "Best val Acc: 0.000216\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = mdl.train_model(model_ft, dataloaders_dict, device, criterion, optimizer_ft, num_epochs=num_epochs,print_every = 5 , is_inception=(model_name==\"inception\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
